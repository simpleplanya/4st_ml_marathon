{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import stdout\n",
    "from collections import OrderedDict\n",
    "from contextlib import contextmanager\n",
    "from inspect import isclass\n",
    "\n",
    "import tablib\n",
    "from docopt import docopt\n",
    "from sqlalchemy import create_engine, exc, inspect, text\n",
    "\n",
    "\n",
    "def isexception(obj):\n",
    "    \"\"\"Given an object, return a boolean indicating whether it is an instance\n",
    "    or subclass of :py:class:`Exception`.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, Exception):\n",
    "        return True\n",
    "    if isclass(obj) and issubclass(obj, Exception):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "class Record(object):\n",
    "    \"\"\"A row, from a query, from a database.\"\"\"\n",
    "    __slots__ = ('_keys', '_values')\n",
    "\n",
    "    def __init__(self, keys, values):\n",
    "        self._keys = keys\n",
    "        self._values = values\n",
    "\n",
    "        # Ensure that lengths match properly.\n",
    "        assert len(self._keys) == len(self._values)\n",
    "\n",
    "    def keys(self):\n",
    "        \"\"\"Returns the list of column names from the query.\"\"\"\n",
    "        return self._keys\n",
    "\n",
    "    def values(self):\n",
    "        \"\"\"Returns the list of values from the query.\"\"\"\n",
    "        return self._values\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<Record {}>'.format(self.export('json')[1:-1])\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        # Support for index-based lookup.\n",
    "        if isinstance(key, int):\n",
    "            return self.values()[key]\n",
    "\n",
    "        # Support for string-based lookup.\n",
    "        if key in self.keys():\n",
    "            i = self.keys().index(key)\n",
    "            if self.keys().count(key) > 1:\n",
    "                raise KeyError(\"Record contains multiple '{}' fields.\".format(key))\n",
    "            return self.values()[i]\n",
    "\n",
    "        raise KeyError(\"Record contains no '{}' field.\".format(key))\n",
    "\n",
    "    def __getattr__(self, key):\n",
    "        try:\n",
    "            return self[key]\n",
    "        except KeyError as e:\n",
    "            raise AttributeError(e)\n",
    "\n",
    "    def __dir__(self):\n",
    "        standard = dir(super(Record, self))\n",
    "        # Merge standard attrs with generated ones (from column names).\n",
    "        return sorted(standard + [str(k) for k in self.keys()])\n",
    "\n",
    "    def get(self, key, default=None):\n",
    "        \"\"\"Returns the value for a given key, or default.\"\"\"\n",
    "        try:\n",
    "            return self[key]\n",
    "        except KeyError:\n",
    "            return default\n",
    "\n",
    "    def as_dict(self, ordered=False):\n",
    "        \"\"\"Returns the row as a dictionary, as ordered.\"\"\"\n",
    "        items = zip(self.keys(), self.values())\n",
    "\n",
    "        return OrderedDict(items) if ordered else dict(items)\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        \"\"\"A Tablib Dataset containing the row.\"\"\"\n",
    "        data = tablib.Dataset()\n",
    "        data.headers = self.keys()\n",
    "\n",
    "        row = _reduce_datetimes(self.values())\n",
    "        data.append(row)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def export(self, format, **kwargs):\n",
    "        \"\"\"Exports the row to the given format.\"\"\"\n",
    "        return self.dataset.export(format, **kwargs)\n",
    "\n",
    "\n",
    "class RecordCollection(object):\n",
    "    \"\"\"A set of excellent Records from a query.\"\"\"\n",
    "    def __init__(self, rows):\n",
    "        self._rows = rows\n",
    "        self._all_rows = []\n",
    "        self.pending = True\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<RecordCollection size={} pending={}>'.format(len(self), self.pending)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate over all rows, consuming the underlying generator\n",
    "        only when necessary.\"\"\"\n",
    "        i = 0\n",
    "        while True:\n",
    "            # Other code may have iterated between yields,\n",
    "            # so always check the cache.\n",
    "            if i < len(self):\n",
    "                yield self[i]\n",
    "            else:\n",
    "                # Throws StopIteration when done.\n",
    "                # Prevent StopIteration bubbling from generator, following https://www.python.org/dev/peps/pep-0479/\n",
    "                try:\n",
    "                    yield next(self)\n",
    "                except StopIteration:\n",
    "                    return\n",
    "            i += 1\n",
    "\n",
    "    def next(self):\n",
    "        return self.__next__()\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            nextrow = next(self._rows)\n",
    "            self._all_rows.append(nextrow)\n",
    "            return nextrow\n",
    "        except StopIteration:\n",
    "            self.pending = False\n",
    "            raise StopIteration('RecordCollection contains no more rows.')\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        is_int = isinstance(key, int)\n",
    "\n",
    "        # Convert RecordCollection[1] into slice.\n",
    "        if is_int:\n",
    "            key = slice(key, key + 1)\n",
    "\n",
    "        while len(self) < key.stop or key.stop is None:\n",
    "            try:\n",
    "                next(self)\n",
    "            except StopIteration:\n",
    "                break\n",
    "\n",
    "        rows = self._all_rows[key]\n",
    "        if is_int:\n",
    "            return rows[0]\n",
    "        else:\n",
    "            return RecordCollection(iter(rows))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._all_rows)\n",
    "\n",
    "    def export(self, format, **kwargs):\n",
    "        \"\"\"Export the RecordCollection to a given format (courtesy of Tablib).\"\"\"\n",
    "        return self.dataset.export(format, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        \"\"\"A Tablib Dataset representation of the RecordCollection.\"\"\"\n",
    "        # Create a new Tablib Dataset.\n",
    "        data = tablib.Dataset()\n",
    "\n",
    "        # If the RecordCollection is empty, just return the empty set\n",
    "        # Check number of rows by typecasting to list\n",
    "        if len(list(self)) == 0:\n",
    "            return data\n",
    "\n",
    "        # Set the column names as headers on Tablib Dataset.\n",
    "        first = self[0]\n",
    "\n",
    "        data.headers = first.keys()\n",
    "        for row in self.all():\n",
    "            row = _reduce_datetimes(row.values())\n",
    "            data.append(row)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def all(self, as_dict=False, as_ordereddict=False):\n",
    "        \"\"\"Returns a list of all rows for the RecordCollection. If they haven't\n",
    "        been fetched yet, consume the iterator and cache the results.\"\"\"\n",
    "\n",
    "        # By calling list it calls the __iter__ method\n",
    "        rows = list(self)\n",
    "\n",
    "        if as_dict:\n",
    "            return [r.as_dict() for r in rows]\n",
    "        elif as_ordereddict:\n",
    "            return [r.as_dict(ordered=True) for r in rows]\n",
    "\n",
    "        return rows\n",
    "\n",
    "    def as_dict(self, ordered=False):\n",
    "        return self.all(as_dict=not(ordered), as_ordereddict=ordered)\n",
    "\n",
    "    def first(self, default=None, as_dict=False, as_ordereddict=False):\n",
    "        \"\"\"Returns a single record for the RecordCollection, or `default`. If\n",
    "        `default` is an instance or subclass of Exception, then raise it\n",
    "        instead of returning it.\"\"\"\n",
    "\n",
    "        # Try to get a record, or return/raise default.\n",
    "        try:\n",
    "            record = self[0]\n",
    "        except IndexError:\n",
    "            if isexception(default):\n",
    "                raise default\n",
    "            return default\n",
    "\n",
    "        # Cast and return.\n",
    "        if as_dict:\n",
    "            return record.as_dict()\n",
    "        elif as_ordereddict:\n",
    "            return record.as_dict(ordered=True)\n",
    "        else:\n",
    "            return record\n",
    "\n",
    "    def one(self, default=None, as_dict=False, as_ordereddict=False):\n",
    "        \"\"\"Returns a single record for the RecordCollection, ensuring that it\n",
    "        is the only record, or returns `default`. If `default` is an instance\n",
    "        or subclass of Exception, then raise it instead of returning it.\"\"\"\n",
    "\n",
    "        # Ensure that we don't have more than one row.\n",
    "        try:\n",
    "            self[1]\n",
    "        except IndexError:\n",
    "            return self.first(default=default, as_dict=as_dict, as_ordereddict=as_ordereddict)\n",
    "        else:\n",
    "            raise ValueError('RecordCollection contained more than one row. '\n",
    "                             'Expects only one row when using '\n",
    "                             'RecordCollection.one')\n",
    "\n",
    "    def scalar(self, default=None):\n",
    "        \"\"\"Returns the first column of the first row, or `default`.\"\"\"\n",
    "        row = self.one()\n",
    "        return row[0] if row else default\n",
    "\n",
    "\n",
    "class Database(object):\n",
    "    \"\"\"A Database. Encapsulates a url and an SQLAlchemy engine with a pool of\n",
    "    connections.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, db_url=None, **kwargs):\n",
    "        # If no db_url was provided, fallback to $DATABASE_URL.\n",
    "        self.db_url = db_url or os.environ.get('DATABASE_URL')\n",
    "\n",
    "        if not self.db_url:\n",
    "            raise ValueError('You must provide a db_url.')\n",
    "\n",
    "        # Create an engine.\n",
    "        self._engine = create_engine(self.db_url, **kwargs)\n",
    "        self.open = True\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Closes the Database.\"\"\"\n",
    "        self._engine.dispose()\n",
    "        self.open = False\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc, val, traceback):\n",
    "        self.close()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<Database open={}>'.format(self.open)\n",
    "\n",
    "    def get_table_names(self, internal=False):\n",
    "        \"\"\"Returns a list of table names for the connected database.\"\"\"\n",
    "\n",
    "        # Setup SQLAlchemy for Database inspection.\n",
    "        return inspect(self._engine).get_table_names()\n",
    "\n",
    "    def get_connection(self):\n",
    "        \"\"\"Get a connection to this Database. Connections are retrieved from a\n",
    "        pool.\n",
    "        \"\"\"\n",
    "        if not self.open:\n",
    "            raise exc.ResourceClosedError('Database closed.')\n",
    "\n",
    "        return Connection(self._engine.connect())\n",
    "\n",
    "    def query(self, query, fetchall=False, **params):\n",
    "        \"\"\"Executes the given SQL query against the Database. Parameters can,\n",
    "        optionally, be provided. Returns a RecordCollection, which can be\n",
    "        iterated over to get result rows as dictionaries.\n",
    "        \"\"\"\n",
    "        with self.get_connection() as conn:\n",
    "            return conn.query(query, fetchall, **params)\n",
    "\n",
    "    def bulk_query(self, query, *multiparams):\n",
    "        \"\"\"Bulk insert or update.\"\"\"\n",
    "\n",
    "        with self.get_connection() as conn:\n",
    "            conn.bulk_query(query, *multiparams)\n",
    "\n",
    "    def query_file(self, path, fetchall=False, **params):\n",
    "        \"\"\"Like Database.query, but takes a filename to load a query from.\"\"\"\n",
    "\n",
    "        with self.get_connection() as conn:\n",
    "            return conn.query_file(path, fetchall, **params)\n",
    "\n",
    "    def bulk_query_file(self, path, *multiparams):\n",
    "        \"\"\"Like Database.bulk_query, but takes a filename to load a query from.\"\"\"\n",
    "\n",
    "        with self.get_connection() as conn:\n",
    "            conn.bulk_query_file(path, *multiparams)\n",
    "\n",
    "    @contextmanager\n",
    "    def transaction(self):\n",
    "        \"\"\"A context manager for executing a transaction on this Database.\"\"\"\n",
    "\n",
    "        conn = self.get_connection()\n",
    "        tx = conn.transaction()\n",
    "        try:\n",
    "            yield conn\n",
    "            tx.commit()\n",
    "        except:\n",
    "            tx.rollback()\n",
    "        finally:\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "class Connection(object):\n",
    "    \"\"\"A Database connection.\"\"\"\n",
    "\n",
    "    def __init__(self, connection):\n",
    "        self._conn = connection\n",
    "        self.open = not connection.closed\n",
    "\n",
    "    def close(self):\n",
    "        self._conn.close()\n",
    "        self.open = False\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc, val, traceback):\n",
    "        self.close()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<Connection open={}>'.format(self.open)\n",
    "\n",
    "    def query(self, query, fetchall=False, **params):\n",
    "        \"\"\"Executes the given SQL query against the connected Database.\n",
    "        Parameters can, optionally, be provided. Returns a RecordCollection,\n",
    "        which can be iterated over to get result rows as dictionaries.\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the given query.\n",
    "        cursor = self._conn.execute(text(query), **params) # TODO: PARAMS GO HERE\n",
    "\n",
    "        # Row-by-row Record generator.\n",
    "        row_gen = (Record(cursor.keys(), row) for row in cursor)\n",
    "\n",
    "        # Convert psycopg2 results to RecordCollection.\n",
    "        results = RecordCollection(row_gen)\n",
    "\n",
    "        # Fetch all results if desired.\n",
    "        if fetchall:\n",
    "            results.all()\n",
    "\n",
    "        return results\n",
    "\n",
    "    def bulk_query(self, query, *multiparams):\n",
    "        \"\"\"Bulk insert or update.\"\"\"\n",
    "\n",
    "        self._conn.execute(text(query), *multiparams)\n",
    "\n",
    "    def query_file(self, path, fetchall=False, **params):\n",
    "        \"\"\"Like Connection.query, but takes a filename to load a query from.\"\"\"\n",
    "\n",
    "        # If path doesn't exists\n",
    "        if not os.path.exists(path):\n",
    "            raise IOError(\"File '{}' not found!\".format(path))\n",
    "\n",
    "        # If it's a directory\n",
    "        if os.path.isdir(path):\n",
    "            raise IOError(\"'{}' is a directory!\".format(path))\n",
    "\n",
    "        # Read the given .sql file into memory.\n",
    "        with open(path) as f:\n",
    "            query = f.read()\n",
    "\n",
    "        # Defer processing to self.query method.\n",
    "        return self.query(query=query, fetchall=fetchall, **params)\n",
    "\n",
    "    def bulk_query_file(self, path, *multiparams):\n",
    "        \"\"\"Like Connection.bulk_query, but takes a filename to load a query\n",
    "        from.\n",
    "        \"\"\"\n",
    "\n",
    "         # If path doesn't exists\n",
    "        if not os.path.exists(path):\n",
    "            raise IOError(\"File '{}'' not found!\".format(path))\n",
    "\n",
    "        # If it's a directory\n",
    "        if os.path.isdir(path):\n",
    "            raise IOError(\"'{}' is a directory!\".format(path))\n",
    "\n",
    "        # Read the given .sql file into memory.\n",
    "        with open(path) as f:\n",
    "            query = f.read()\n",
    "\n",
    "        self._conn.execute(text(query), *multiparams)\n",
    "\n",
    "    def transaction(self):\n",
    "        \"\"\"Returns a transaction object. Call ``commit`` or ``rollback``\n",
    "        on the returned object as appropriate.\"\"\"\n",
    "\n",
    "        return self._conn.begin()\n",
    "\n",
    "def _reduce_datetimes(row):\n",
    "    \"\"\"Receives a row, converts datetimes to strings.\"\"\"\n",
    "\n",
    "    row = list(row)\n",
    "\n",
    "    for i in range(len(row)):\n",
    "        if hasattr(row[i], 'isoformat'):\n",
    "            row[i] = row[i].isoformat()\n",
    "    return tuple(row)\n",
    "\n",
    "def cli():\n",
    "    supported_formats = 'csv tsv json yaml html xls xlsx dbf latex ods'.split()\n",
    "    formats_lst=\", \".join(supported_formats)\n",
    "    cli_docs =\"\"\"Records: SQL for Humans™\n",
    "A Kenneth Reitz project.\n",
    "Usage:\n",
    "  records <query> [<format>] [<params>...] [--url=<url>]\n",
    "  records (-h | --help)\n",
    "Options:\n",
    "  -h --help     Show this screen.\n",
    "  --url=<url>   The database URL to use. Defaults to $DATABASE_URL.\n",
    "Supported Formats:\n",
    "   %(formats_lst)s\n",
    "   Note: xls, xlsx, dbf, and ods formats are binary, and should only be\n",
    "         used with redirected output e.g. '$ records sql xls > sql.xls'.\n",
    "Query Parameters:\n",
    "    Query parameters can be specified in key=value format, and injected\n",
    "    into your query in :key format e.g.:\n",
    "    $ records 'select * from repos where language ~= :lang' lang=python\n",
    "Notes:\n",
    "  - While you may specify a database connection string with --url, records\n",
    "    will automatically default to the value of $DATABASE_URL, if available.\n",
    "  - Query is intended to be the path of a SQL file, however a query string\n",
    "    can be provided instead. Use this feature discernfully; it's dangerous.\n",
    "  - Records is intended for report-style exports of database queries, and\n",
    "    has not yet been optimized for extremely large data dumps.\n",
    "    \"\"\" % dict(formats_lst=formats_lst)\n",
    "\n",
    "    # Parse the command-line arguments.\n",
    "    arguments = docopt(cli_docs)\n",
    "\n",
    "    query = arguments['<query>']\n",
    "    params = arguments['<params>']\n",
    "    format = arguments.get('<format>')\n",
    "    if format and \"=\" in format:\n",
    "        del arguments['<format>']\n",
    "        arguments['<params>'].append(format)\n",
    "        format = None\n",
    "    if format and format not in supported_formats:\n",
    "        print('%s format not supported.' % format)\n",
    "        print('Supported formats are %s.' % formats_lst)\n",
    "        exit(62)\n",
    "\n",
    "    # Can't send an empty list if params aren't expected.\n",
    "    try:\n",
    "        params = dict([i.split('=') for i in params])\n",
    "    except ValueError:\n",
    "        print('Parameters must be given in key=value format.')\n",
    "        exit(64)\n",
    "\n",
    "    # Be ready to fail on missing packages\n",
    "    try:\n",
    "        # Create the Database.\n",
    "        db = Database(arguments['--url'])\n",
    "\n",
    "        # Execute the query, if it is a found file.\n",
    "        if os.path.isfile(query):\n",
    "            rows = db.query_file(query, **params)\n",
    "\n",
    "        # Execute the query, if it appears to be a query string.\n",
    "        elif len(query.split()) > 2:\n",
    "            rows = db.query(query, **params)\n",
    "\n",
    "        # Otherwise, say the file wasn't found.\n",
    "        else:\n",
    "            print('The given query could not be found.')\n",
    "            exit(66)\n",
    "\n",
    "        # Print results in desired format.\n",
    "        if format:\n",
    "            content = rows.export(format)\n",
    "            if isinstance(content, bytes):\n",
    "                print_bytes(content)\n",
    "            else:\n",
    "                print(content)\n",
    "        else:\n",
    "            print(rows.dataset)\n",
    "    except ImportError as impexc:\n",
    "        print(impexc.msg)\n",
    "        print(\"Used database or format require a package, which is missing.\")\n",
    "        print(\"Try to install missing packages.\")\n",
    "        exit(60)\n",
    "\n",
    "\n",
    "def print_bytes(content):\n",
    "    try:\n",
    "        stdout.buffer.write(content)\n",
    "    except AttributeError:\n",
    "        stdout.write(content)\n",
    "\n",
    "\n",
    "# Run the CLI when executed directly.\n",
    "if __name__ == '__main__':\n",
    "    cli()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
